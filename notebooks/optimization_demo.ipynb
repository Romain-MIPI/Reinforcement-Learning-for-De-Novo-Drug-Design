{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z-4tsrIAVLwC",
        "outputId": "322d78c7-44f6-43cd-a82f-6691f5d3ddf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.2.1)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "!pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Romain-MIPI/Reinforcement-Learning-for-De-Novo-Drug-Design.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWgT1WPqVtAP",
        "outputId": "f18b9096-1472-4325-9424-c3c8ffb5aeb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Reinforcement-Learning-for-De-Novo-Drug-Design' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Reinforcement-Learning-for-De-Novo-Drug-Design"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WANfmJpzVugN",
        "outputId": "71239baf-0353-4790-d3df-1aa5fb49e36d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Reinforcement-Learning-for-De-Novo-Drug-Design\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole"
      ],
      "metadata": {
        "id": "xIWV2-0yVxy4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, f1_score, recall_score, precision_score\n",
        "import pandas as pd\n",
        "import copy\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JzmB746uVyJR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "KHXyA5tUVzpy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm, trange\n",
        "from rdkit import Chem, DataStructs\n",
        "from models.rnn_generative import RNNGenerative\n",
        "from models.generator_data import GeneratorData\n",
        "from models.utils import canonical_smiles\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "w-15vf_FspLK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem import QED\n",
        "\n",
        "gen_data_path = './data/clean_020724_all_with_update.csv'\n",
        "data = pd.read_csv(gen_data_path)\n",
        "smiles = data['SMILES'].values"
      ],
      "metadata": {
        "id": "gjB9ciuOV1mT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.utils import get_tokens\n",
        "my_tokens, _, _ = get_tokens(smiles)\n",
        "l_tokens = list(my_tokens) + ['<', '>']"
      ],
      "metadata": {
        "id": "vtYxWf4zWcD3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter=',',\n",
        "                         cols_to_read=[12], keep_header=False, tokens=l_tokens)"
      ],
      "metadata": {
        "id": "W7ZGjxwIs8oI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bar(prediction, n_to_generate):\n",
        "    value, count = np.unique(prediction, return_counts=True)\n",
        "    print(\"Percentage predict class 0 (inactive) :\", count[np.where(value==0)]/len(prediction))\n",
        "    print(\"Percentage predict class 1 (weakly actif) :\", count[np.where(value==1)]/len(prediction))\n",
        "    print(\"Percentage predict class 2 (strongly actif) :\", count[np.where(value==2)]/len(prediction))\n",
        "    print(\"Proportion of valid SMILES:\", len(prediction)/n_to_generate)\n",
        "    ax = plt.bar(value, count)\n",
        "    ax.set(xlabel='Predicted class',\n",
        "           y_label='Number of molecules',\n",
        "           title='Distribution of predicted class for generated molecules')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RNfLTK6zs_GM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_and_update(generator, predictor, n_to_generate):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "\n",
        "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
        "    unique_smiles = list(np.unique(sanitized))[1:]\n",
        "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, use_tqdm=True)\n",
        "\n",
        "    plot_bar(prediction, n_to_generate)\n",
        "\n",
        "    return smiles, prediction"
      ],
      "metadata": {
        "id": "3hAsq6vItJIq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbo_Sl6u40hj",
        "outputId": "36df9c5c-13b8-43d5-ea48-ea4e9c402d8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 500\n",
        "stack_width = 500\n",
        "stack_depth = 200\n",
        "layer_type = 'GRU'\n",
        "lr = 0.001\n",
        "optimizer_instance = torch.optim.Adadelta\n",
        "\n",
        "my_generator = RNNGenerative(input_size=gen_data.n_characters, hidden_size=hidden_size,\n",
        "                             output_size=gen_data.n_characters, layer_type=layer_type,\n",
        "                             n_layers=1, is_bidirectional=False, has_stack=True,\n",
        "                             stack_width=stack_width, stack_depth=stack_depth,\n",
        "                             use_cuda=use_cuda,\n",
        "                             optimizer_instance=optimizer_instance, lr=lr)"
      ],
      "metadata": {
        "id": "WZascqZgtKuE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './data/checkpoints/generator/checkpoint_stack_rnn'"
      ],
      "metadata": {
        "id": "W9w7GVJFtWWu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training generative model\n",
        "\n",
        "losses = my_generator.fit(gen_data, 50000)\n",
        "plt.plot(losses)\n",
        "my_generator.evaluate(gen_data)\n",
        "my_generator.save_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "mGWp6xGetbsb",
        "outputId": "7f120f11-8ba6-46f0-f3e4-d51a4702f67d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining in progress...:   0%|          | 0/50000 [00:00<?, ?it/s]/content/Reinforcement-Learning-for-De-Novo-Drug-Design/models/generator_data.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(tensor).cuda()\n",
            "Training in progress...:   0%|          | 3/50000 [00:01<4:46:40,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-45547ab21bd9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training generative model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Reinforcement-Learning-for-De-Novo-Drug-Design/models/rnn_generative.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, n_iterations, all_losses, print_every, plot_every, augment)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_augmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Reinforcement-Learning-for-De-Novo-Drug-Design/models/rnn_generative.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inp, target)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_generator.load_model(model_path)"
      ],
      "metadata": {
        "id": "0Z0Z3runtcgQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.rnn_predictor import RNNPredictor\n",
        "\n",
        "path_to_params = './data/checkpoints/classification/model_parameters.pkl'\n",
        "path_to_checkpoint = './data/checkpoints/classification/fold_'\n",
        "\n",
        "my_predictor = RNNPredictor(path_to_params, path_to_checkpoint, l_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Hnfce70AtmDy",
        "outputId": "ca24cba0-a39f-4c10-a852-aea5a01c0e33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models.embedding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2169dd21dea4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_to_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/checkpoints/classification/fold_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Reinforcement-Learning-for-De-Novo-Drug-Design/models/rnn_predictor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_to_parameters_dict, path_to_checkpoint, tokens)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmiles2Label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_parameters_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.embedding'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_unbiased, prediction_unbiased = estimate_and_update(my_generator,\n",
        "                                                           my_predictor,\n",
        "                                                           n_to_generate=10000)"
      ],
      "metadata": {
        "id": "8OKdUWRqt05j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_generator_2 = RNNGenerator(input_size=gen_data.n_characters,\n",
        "                                hidden_size=hidden_size,\n",
        "                                output_size=gen_data.n_characters,\n",
        "                                layer_type=layer_type,\n",
        "                                n_layers=1, is_bidirectional=False, has_stack=True,\n",
        "                                stack_width=stack_width, stack_depth=stack_depth,\n",
        "                                use_cuda=use_cuda,\n",
        "                                optimizer_instance=optimizer_instance, lr=lr)\n",
        "\n",
        "my_generator_2.load_model(model_path)"
      ],
      "metadata": {
        "id": "Kfq6xYX8t8ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_moving_average(previous_values, new_value, ma_window_size=10):\n",
        "    value_ma = np.sum(previous_values[-(ma_window_size-1):]) + new_value\n",
        "    value_ma = value_ma/(len(previous_values[-(ma_window_size-1):]) + 1)\n",
        "    return value_ma"
      ],
      "metadata": {
        "id": "-YxuQpzsuJJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reward_activity(smile, predictor, invalid_reward=0.0):\n",
        "    _, prediction, invalid_smiles = predictor.predict([smile])\n",
        "    if len(nan_smiles) == 1:\n",
        "        return invalid_reward\n",
        "    if (prediction[0] == 2):\n",
        "        return 11.0\n",
        "    elif (prediction[0] == 1):\n",
        "        return 6.0\n",
        "    else:\n",
        "        return 1.0"
      ],
      "metadata": {
        "id": "kNWssSmuuJl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up some parameters for the experiment\n",
        "n_to_generate = 200\n",
        "n_policy_replay = 10\n",
        "n_policy = 15\n",
        "n_iterations = 60\n",
        "\n",
        "RL_activity = Reinforcement(my_generator_2, my_predictor, get_reward_activity)\n",
        "\n",
        "rewards = []\n",
        "rl_losses = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    for j in trange(n_policy, desc='Policy gradient...'):\n",
        "        cur_reward, cur_loss = RL_activity.policy_gradient(gen_data)\n",
        "        rewards.append(simple_moving_average(rewards, cur_reward))\n",
        "        rl_losses.append(simple_moving_average(rl_losses, cur_loss))\n",
        "\n",
        "    plt.plot(rewards)\n",
        "    plt.xlabel('Training iteration')\n",
        "    plt.ylabel('Average reward')\n",
        "    plt.show()\n",
        "    plt.plot(rl_losses)\n",
        "    plt.xlabel('Training iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    smiles_cur, prediction_cur = estimate_and_update(RL_activity.generator,\n",
        "                                                     my_predictor,\n",
        "                                                     n_to_generate)"
      ],
      "metadata": {
        "id": "THGzfWe4uMne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_biased, prediction_biased = estimate_and_update(RL_activity.generator,\n",
        "                                                       my_predictor,\n",
        "                                                       n_to_generate=10000)"
      ],
      "metadata": {
        "id": "n5TlAaNuu5cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_val = [0, 1, 2]\n",
        "\n",
        "value1, count1 = np.unique(prediction_biased, return_counts=True)\n",
        "value2, count2 = np.unique(prediction_biased, return_counts=True)\n",
        "\n",
        "if len(value1) != len(class_val):\n",
        "    tmp = []\n",
        "    for c in class_val:\n",
        "        if c not in value1:\n",
        "            tmp.append(count1[np.where(value1==c)])\n",
        "        else:\n",
        "            tmp.append(0)\n",
        "    count1 = tmp\n",
        "if len(value2) != len(class_val):\n",
        "    tmp = []\n",
        "    for c in class_val:\n",
        "        if c not in value2:\n",
        "            tmp.append(count2[np.where(value2==c)])\n",
        "        else:\n",
        "            tmp.append(0)\n",
        "    count2 = tmp\n",
        "\n",
        "w, x = 0.4, np.arange(len(labels))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(x - w/2, count1, width=w, label='unbiased')\n",
        "ax.bar(x + w/2, count2, width=w, label='biased')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(['class 0', 'class 1', 'class 2'])\n",
        "ax.set_ylabel('Number of molecules')\n",
        "ax.set_title('distribution of generated molecules')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dlFlY07nzmnf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}